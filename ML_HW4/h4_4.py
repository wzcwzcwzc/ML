# -*- coding: utf-8 -*-
"""h4_4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XTIHhZ0KyE-olGakOji8oj9-FBq-HTuW
"""

import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.neighbors import KNeighborsClassifier
from sklearn import model_selection
from sklearn.metrics import accuracy_score, confusion_matrix
import datetime
from sklearn import svm
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import confusion_matrix
import warnings

"""a. Load the dataset and display 10 representative images from each class."""

fashion_mnist = keras.datasets.fashion_mnist 
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
# create 10 folds of dataset by using label 0-9
s = set([])
m = []
for idx in range(len(train_images)):
  if train_labels[idx] not in s:
    s.add(train_labels[idx])
    m.append(train_images[idx])
    if len(s) == 10:
      break

plt.figure(figsize=(12,4))
for index in range(10):
  plt.subplot(1,10,index+1)
  plt.imshow(m[index],cmap=plt.cm.gray)

"""b. Implement the following classification methods: k-NN, logistic regression, and support vector machines (with linear and rbf kernels). You can use sklearn.

In order to save time, I just use 1000 dataset to do the experiment

KNN
"""

starttime = datetime.datetime.now()

K = np.arange(1,61,3)
knn_testing_error = {}

nsamples, nx, ny = train_images[:1000].shape
d2_train_dataset = train_images[:1000].reshape((nsamples,nx*ny))
nsamples1, nx1, ny1 = test_images[:100].shape
d2_test_dataset = test_images[:100].reshape((nsamples1,nx1*ny1))

for k in K:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(d2_train_dataset, train_labels[:1000])
    knn_testing_error.update({k: 1-accuracy_score(test_labels[:100], knn.predict(d2_test_dataset))})


print(min(knn_testing_error, key=knn_testing_error.get))
knn_test_error =knn_testing_error[min(knn_testing_error, key=knn_testing_error.get)]
print(knn_test_error)
endtime = datetime.datetime.now()
knn_time = (endtime - starttime).seconds

"""logistic"""

starttime = datetime.datetime.now()

X = d2_train_dataset
y = train_labels[:1000]
c_set = np.logspace(-4, 4, 10)
scores_set = {}
for c in c_set:
    clf = LogisticRegression( C=c)
    scores = cross_val_score(clf, X, y=y).mean()
    scores_set["c={}".format(c)] = scores
print(scores_set)
optimal_para = max(scores_set, key=scores_set.get)
optimal_c = optimal_para.split('=')[1]

clf = LogisticRegression(C=float(optimal_c))
clf.fit(X,y)
c_matrix = confusion_matrix(y, clf.predict(X))
print(c_matrix)
y_pred = clf.predict(d2_test_dataset)
c_matrix_test = confusion_matrix(test_labels[:100], y_pred)
print(c_matrix_test)
logit_test_error = 1-clf.score(d2_test_dataset, test_labels[:100])
print(logit_test_error)

endtime = datetime.datetime.now()
logit_time = (endtime - starttime).seconds

"""rbf"""

# rbf
starttime = datetime.datetime.now()

c_set = np.logspace(-4, 4, 5)
scores_set = {}
for c in c_set:
      scv = svm.SVC(C=c,kernel='rbf',gamma='scale',decision_function_shape='ovr') 
      scores = cross_val_score(scv, X, y=y).mean()
      scores_set["c={}".format(c)] = scores
print(scores_set)
print(max(scores_set, key=scores_set.get))
optimal_para = max(scores_set, key=scores_set.get)
optimal_c = optimal_para.split('=')[1]


scv = svm.SVC(C=float(optimal_c), kernel='rbf', gamma='scale', decision_function_shape='ovr')
scv.fit(X,y)
rbfSVC_test_error = 1-scv.score(d2_test_dataset, test_labels[:100])
print(rbfSVC_test_error)

endtime = datetime.datetime.now()
rbf_time = (endtime - starttime).seconds

"""linear svm"""

starttime = datetime.datetime.now()

c_set = np.logspace(-4, 4, 8)
scores_set = {}
for c in c_set:
    scv = svm.LinearSVC(penalty='l1',C=c,multi_class='ovr',dual=False) 
    scores = cross_val_score(scv, X, y=y).mean()
    scores_set["c={}".format(c)] = scores
print(scores_set)
optimal_para = max(scores_set, key=scores_set.get)
optimal_c = optimal_para.split('=')[1]

scv = svm.LinearSVC(C=float(optimal_c), multi_class='ovr', dual=False)
scv.fit(X,y)
linSVC_test_error = 1-scv.score(d2_test_dataset, test_labels[:100])
print(linSVC_test_error)

endtime = datetime.datetime.now()
lin_time = (endtime - starttime).seconds

"""c. Report best possible test-error performances by tuning hyperparameters in each of your methods.




d. Report train- and test-running time of each of your methods in the form of a table, and comment on the relative tradeoffs across the different methods.
"""

cell_text = [['test_error',knn_test_error,logit_test_error,rbfSVC_test_error,linSVC_test_error],['time_used',knn_time,logit_time,rbf_time,lin_time]]
res_df = pd.DataFrame(np.array(cell_text),columns = ('Feature','KNN', 'Logistic Regression', 'rbf SVM', 'linear SVM'))
res_df