# -*- coding: utf-8 -*-
"""HW2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PMAazbFF3xXpPQrZ1hxPp9smeaQBW8IC
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import pandas as pd
from sklearn import datasets, linear_model

kwargs = {'linewidth' : 3.5}
font = {'weight' : 'normal', 'size'   : 24}
matplotlib.rc('font', **font)

def error_plot(ys, yscale='log'):
  plt.figure(figsize=(5, 5))
  plt.xlabel('Step')
  plt.ylabel('Error')
  plt.yscale(yscale)
  plt.plot(range(len(ys)), ys, **kwargs)

def gradient_descent(init, steps, grad):
  xs = [init]
  for step in steps:
    # grad() -> lambda
    xs.append(xs[-1] - step * grad(xs[-1])) 
  return xs

def mse(x, y, w):
  return np.mean(np.linalg.norm(x.dot(w)-y)**2)

def mse_gradient(x, y, w):
  return x.T.dot(x.dot(w)-y)

def cal_r_square(x, y, ws):
  predict_y = x.dot(ws[-1])
  RSS = np.mean((predict_y - y)**2) / (np.std(y)**2)
  Rsq = 1 - RSS
  return Rsq

def Driver(data, learning_rate, epochs, gradient_type):
  res = gradient_descent(data, [learning_rate] * epochs, gradient_type)
  return res

# get the data
diabetes = datasets.load_diabetes()
X = diabetes.data
Y = diabetes.target

# divide data into train set and test set
x_train = X[0:300]
x_test = X[300:]
y_train = Y[0:300] - np.mean(Y[0:300])
y_test = Y[300:] - np.mean(Y[300:])

objective = lambda w: mse(x_train,y_train,w)
gradient = lambda w: mse_gradient(x_train,y_train,w)

# set w0
w0 = np.array([2000] * 10)
# calculate ws by using gradient descent
ws = Driver(w0, 0.1, 500, gradient)

error_plot([objective(w) for w in ws])

rsq = cal_r_square(x_train, y_train, ws)
print(f'the train r^2 value is {rsq}')

# test part
test_rsq = cal_r_square(x_test, y_test, ws)
print(f'the test r^2 value is {test_rsq}')